name: 'Setup, Run Crawler, and Commit Data'
description: 'Sets up environment, runs the specified crawler task, and commits the results.'

inputs:
  task_name:
    description: 'The name of the crawler task to run (e.g., TASK_1)'
    required: true
  # 接收 GITHUB_TOKEN，用于后续的 stefanzweifel/git-auto-commit-action
  github_token:
    description: 'The GITHUB_TOKEN for committing changes'
    required: true

runs:
  using: "composite"
  steps:
    # 1. 设置 Python 和依赖 (由调用 Job 检出代码后，此处可以直接使用)
    - name: Set up Python and Install dependencies
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      shell: bash
      run: pip install -r requirements.txt

    # 2. 最佳实践：时区修正
    - name: Set Timezone to Asia/Shanghai (CST)
      shell: bash
      run: echo "TZ=Asia/Shanghai" >> $GITHUB_ENV

    # 3. 核心：运行爬虫
    - name: Run Crawler for ${{ inputs.task_name }}
      shell: bash
      run: python crawler.py ${{ inputs.task_name }}

    # 4. 原子性提交
    - name: Commit and Push new data
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "SCHEDULER: Auto-update data [${{ inputs.task_name }}]."
        file_pattern: 'zgyd/*.json zgyd/metadata.json'
        commit_user_name: 'github-actions[bot]'
        commit_user_email: 'github-actions[bot]@users.noreply.github.com'
        # 使用从 inputs 传入的 token
        token: ${{ inputs.github_token }}
        # 关键修复：解决并发 push 冲突
        push_options: '--force-with-lease'