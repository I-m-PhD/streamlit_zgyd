# .github/actions/sop/action.yml

name: 'Setup, Run Crawler, and Commit Data'
description: 'Sets up environment, runs the specified crawler task, and commits the results.'

inputs:
  task_name:
    description: 'The name of the crawler task to run (e.g., TASK_1)'
    required: true

runs:
  using: "composite"
  steps:
    # 1. 设置 Python 版本
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'

    # 2. 缓存 Python 依赖
    # 如果 requirements.txt 文件内容不变，则命中缓存，极大地减少安装时间。
    - name: Cache Python dependencies (pip cache)
      uses: actions/cache@v4
      with:
        # 缓存路径：默认的 Python site-packages 目录
        path: ${{ env.pythonLocation }}/lib/python*/site-packages
        # 缓存键：基于操作系统和 requirements.txt 文件的哈希值
        key: ${{ runner.os }}-python-${{ hashFiles('requirements.txt') }}
        # 恢复键：用于匹配较旧的缓存
        restore-keys: |
          ${{ runner.os }}-python-

    # 3. 运行依赖安装
    # 如果缓存命中，此步骤会快速完成或跳过
    - name: Install dependencies
      shell: bash
      run: pip install -r requirements.txt

    # # 4. 时区修正
    # - name: Set Timezone to Asia/Shanghai (CST)
    #   shell: bash
    #   run: echo "TZ=Asia/Shanghai" >> $GITHUB_ENV

    # 5. 运行爬虫
    - name: Run Crawler for ${{ inputs.task_name }}
      shell: bash
      run: python crawler.py ${{ inputs.task_name }}

    # 6. 原子性提交
    - name: Commit and Push new data
      uses: stefanzweifel/git-auto-commit-action@v5
      with:
        commit_message: "SCHEDULER: Auto-update data [${{ inputs.task_name }}]."
        file_pattern: 'zgyd/*.json zgyd/metadata.json'
        commit_user_name: 'github-actions[bot]'
        commit_user_email: 'github-actions[bot]@users.noreply.github.com'
        # V5 版本不再支持 'token' 输入参数，自动使用 Job 的 GITHUB_TOKEN
        push_options: '--force-with-lease'